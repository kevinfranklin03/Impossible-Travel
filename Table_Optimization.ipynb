{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e43926-d3c6-4298-a79d-5770b95dc35a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Configuration\n",
    "# ============================================\n",
    "\n",
    "CATALOG = \"fraud_detection\"\n",
    "SCHEMA = \"raw\"\n",
    "\n",
    "# Table names\n",
    "SILVER_TABLE = f\"{CATALOG}.{SCHEMA}.silver_all_transactions\"\n",
    "GOLD_ALERTS_TABLE = f\"{CATALOG}.{SCHEMA}.gold_fraud_alerts\"\n",
    "METRICS_TABLE = f\"{CATALOG}.{SCHEMA}.gold_fraud_metrics_realtime\"\n",
    "PERFORMANCE_TABLE = f\"{CATALOG}.{SCHEMA}.gold_system_performance\"\n",
    "\n",
    "print(\"✅ Config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee35761-5262-4420-871c-eb93c70887eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA CURRENT TABLE STATISTICS (BEFORE OPTIMIZATION)\n======================================================================\n\n\uD83E\uDD48 Silver Table: fraud_detection.raw.silver_all_transactions\n   Records: 1,110\n   Files: 19\n   Size: 0.09 MB\n\n\uD83E\uDD47 Gold Alerts Table: fraud_detection.raw.gold_fraud_alerts\n   Records: 29\n   Files: 27\n   Size: 0.10 MB\n\n⚠️  Many small files = slow queries!\n   Target: < 5 files per table for best performance\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BEFORE Optimization - Current Stats\n",
    "# ============================================\n",
    "\n",
    "print(\"\uD83D\uDCCA CURRENT TABLE STATISTICS (BEFORE OPTIMIZATION)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Silver table stats\n",
    "silver_count = spark.table(SILVER_TABLE).count()\n",
    "silver_files = spark.sql(f\"DESCRIBE DETAIL {SILVER_TABLE}\").select(\"numFiles\").first()[0]\n",
    "silver_size = spark.sql(f\"DESCRIBE DETAIL {SILVER_TABLE}\").select(\"sizeInBytes\").first()[0]\n",
    "\n",
    "print(f\"\\n\uD83E\uDD48 Silver Table: {SILVER_TABLE}\")\n",
    "print(f\"   Records: {silver_count:,}\")\n",
    "print(f\"   Files: {silver_files}\")\n",
    "print(f\"   Size: {silver_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Gold alerts stats\n",
    "gold_count = spark.table(GOLD_ALERTS_TABLE).count()\n",
    "gold_files = spark.sql(f\"DESCRIBE DETAIL {GOLD_ALERTS_TABLE}\").select(\"numFiles\").first()[0]\n",
    "gold_size = spark.sql(f\"DESCRIBE DETAIL {GOLD_ALERTS_TABLE}\").select(\"sizeInBytes\").first()[0]\n",
    "\n",
    "print(f\"\\n\uD83E\uDD47 Gold Alerts Table: {GOLD_ALERTS_TABLE}\")\n",
    "print(f\"   Records: {gold_count:,}\")\n",
    "print(f\"   Files: {gold_files}\")\n",
    "print(f\"   Size: {gold_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\n⚠️  Many small files = slow queries!\")\n",
    "print(f\"   Target: < 5 files per table for best performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "019c9b90-cf1d-45d1-a768-fbec4563e8ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDD27 OPTIMIZING SILVER TABLE...\n======================================================================\n✅ Silver table optimized in 8.8 seconds\n   - Compacted small files into larger ones\n   - Z-Ordered by card_id and ingest_ts for faster lookups\n\n\uD83D\uDCCA Files BEFORE: 19 → AFTER: 1\n   File reduction: 94.7%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Optimize Silver Table with Z-Ordering\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\uD83D\uDD27 OPTIMIZING SILVER TABLE...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Optimize and Z-Order by frequently queried columns\n",
    "spark.sql(f\"\"\"\n",
    "    OPTIMIZE {SILVER_TABLE}\n",
    "    ZORDER BY (card_id, ingest_ts)\n",
    "\"\"\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"✅ Silver table optimized in {elapsed:.1f} seconds\")\n",
    "print(f\"   - Compacted small files into larger ones\")\n",
    "print(f\"   - Z-Ordered by card_id and ingest_ts for faster lookups\")\n",
    "\n",
    "# Check AFTER stats\n",
    "silver_files_after = spark.sql(f\"DESCRIBE DETAIL {SILVER_TABLE}\").select(\"numFiles\").first()[0]\n",
    "print(f\"\\n\uD83D\uDCCA Files BEFORE: {silver_files} → AFTER: {silver_files_after}\")\n",
    "print(f\"   File reduction: {((silver_files - silver_files_after) / silver_files * 100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83cb1552-f089-48a5-97ad-600950088bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDD27 OPTIMIZING GOLD ALERTS TABLE...\n======================================================================\n✅ Gold alerts optimized in 4.7 seconds\n\n\uD83D\uDCCA Files BEFORE: 27 → AFTER: 1\n   File reduction: 96.3%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Optimize Gold Alerts Table with Z-Ordering\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\uD83D\uDD27 OPTIMIZING GOLD ALERTS TABLE...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Optimize and Z-Order by frequently filtered columns\n",
    "spark.sql(f\"\"\"\n",
    "    OPTIMIZE {GOLD_ALERTS_TABLE}\n",
    "    ZORDER BY (card_id, alert_timestamp, severity)\n",
    "\"\"\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"✅ Gold alerts optimized in {elapsed:.1f} seconds\")\n",
    "\n",
    "# Check AFTER stats\n",
    "gold_files_after = spark.sql(f\"DESCRIBE DETAIL {GOLD_ALERTS_TABLE}\").select(\"numFiles\").first()[0]\n",
    "print(f\"\\n\uD83D\uDCCA Files BEFORE: {gold_files} → AFTER: {gold_files_after}\")\n",
    "print(f\"   File reduction: {((gold_files - gold_files_after) / gold_files * 100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3ae7668-3ab4-405e-a61f-53c7d5307be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA ANALYZING TABLE STATISTICS...\n======================================================================\n\nAnalyzing fraud_detection.raw.silver_all_transactions...\n✅ fraud_detection.raw.silver_all_transactions analyzed\n\nAnalyzing fraud_detection.raw.gold_fraud_alerts...\n✅ fraud_detection.raw.gold_fraud_alerts analyzed\n\nAnalyzing fraud_detection.raw.gold_fraud_metrics_realtime...\n✅ fraud_detection.raw.gold_fraud_metrics_realtime analyzed\n\nAnalyzing fraud_detection.raw.gold_system_performance...\n✅ fraud_detection.raw.gold_system_performance analyzed\n\n✅ ALL TABLES ANALYZED\n   Query optimizer can now make better decisions!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Analyze Table Statistics for Query Optimization\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\uD83D\uDCCA ANALYZING TABLE STATISTICS...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "tables = [SILVER_TABLE, GOLD_ALERTS_TABLE, METRICS_TABLE, PERFORMANCE_TABLE]\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"\\nAnalyzing {table}...\")\n",
    "    spark.sql(f\"ANALYZE TABLE {table} COMPUTE STATISTICS FOR ALL COLUMNS\")\n",
    "    print(f\"✅ {table} analyzed\")\n",
    "\n",
    "print(\"\\n✅ ALL TABLES ANALYZED\")\n",
    "print(\"   Query optimizer can now make better decisions!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87cfaa03-66c1-467c-acd6-21e3489a7223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83E\uDDF9 VACUUMING OLD FILES...\n======================================================================\n⚠️  This removes old file versions to save storage costs\n   Retention: 7 days (168 hours)\n\nVacuuming fraud_detection.raw.silver_all_transactions...\n✅ fraud_detection.raw.silver_all_transactions vacuumed\n\nVacuuming fraud_detection.raw.gold_fraud_alerts...\n✅ fraud_detection.raw.gold_fraud_alerts vacuumed\n\n✅ VACUUM COMPLETE - Storage costs reduced!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Vacuum Old Files (Remove deleted data)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\uD83E\uDDF9 VACUUMING OLD FILES...\")\n",
    "print(\"=\" * 70)\n",
    "print(\"⚠️  This removes old file versions to save storage costs\")\n",
    "print(\"   Retention: 7 days (168 hours)\")\n",
    "\n",
    "RETENTION_HOURS = 168\n",
    "\n",
    "for table in [SILVER_TABLE, GOLD_ALERTS_TABLE]:\n",
    "    print(f\"\\nVacuuming {table}...\")\n",
    "    spark.sql(f\"VACUUM {table} RETAIN {RETENTION_HOURS} HOURS\")\n",
    "    print(f\"✅ {table} vacuumed\")\n",
    "\n",
    "print(\"\\n✅ VACUUM COMPLETE - Storage costs reduced!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f72f5509-a73f-4860-ada6-279ec3b35f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n⚡ TESTING QUERY PERFORMANCE...\n======================================================================\n\nQuery 1: Find fraud for card 1025\n   Results: 5 rows\n   Time: 1242ms\n   Status: ⚠️ SLOW\n\nQuery 2: Fraud alerts in last hour\n   Results: 0 rows\n   Time: 714ms\n   Status: ✅ FAST\n\n======================================================================\n✅ OPTIMIZATION COMPLETE!\n\n\uD83D\uDCA1 Schedule this notebook to run daily at 2 AM\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Test Query Performance (AFTER optimization)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n⚡ TESTING QUERY PERFORMANCE...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import time\n",
    "\n",
    "# Test query 1: Find all fraud for a specific card\n",
    "test_card_id = spark.table(GOLD_ALERTS_TABLE).select(\"card_id\").first()[0]\n",
    "\n",
    "start_time = time.time()\n",
    "result = spark.sql(f\"\"\"\n",
    "    SELECT * \n",
    "    FROM {GOLD_ALERTS_TABLE}\n",
    "    WHERE card_id = {test_card_id}\n",
    "    ORDER BY alert_timestamp DESC\n",
    "\"\"\").count()\n",
    "elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nQuery 1: Find fraud for card {test_card_id}\")\n",
    "print(f\"   Results: {result} rows\")\n",
    "print(f\"   Time: {elapsed_ms:.0f}ms\")\n",
    "print(f\"   Status: {'✅ FAST' if elapsed_ms < 1000 else '⚠️ SLOW'}\")\n",
    "\n",
    "# Test query 2: Recent fraud alerts\n",
    "start_time = time.time()\n",
    "result = spark.sql(f\"\"\"\n",
    "    SELECT * \n",
    "    FROM {GOLD_ALERTS_TABLE}\n",
    "    WHERE alert_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 1 HOUR\n",
    "    ORDER BY alert_timestamp DESC\n",
    "\"\"\").count()\n",
    "elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nQuery 2: Fraud alerts in last hour\")\n",
    "print(f\"   Results: {result} rows\")\n",
    "print(f\"   Time: {elapsed_ms:.0f}ms\")\n",
    "print(f\"   Status: {'✅ FAST' if elapsed_ms < 1000 else '⚠️ SLOW'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ OPTIMIZATION COMPLETE!\")\n",
    "print(\"\\n\uD83D\uDCA1 Schedule this notebook to run daily at 2 AM\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Table_Optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}